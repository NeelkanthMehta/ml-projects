{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Aim\n",
    "\n",
    "GitHub Repo: [stanford_dogs](https://github.com/darthv115/ml-projects/tree/master/stanford_dogs)\n",
    "\n",
    "So, This notebook is basically for pre-processing the input images from the Stanford Dogs dataset which can be downloaded [here](http://vision.stanford.edu/aditya86/ImageNetDogs/).\n",
    "\n",
    "In this notebook, I will use methods to basically make the data in a format to be fed to a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mAnnotation\u001b[0m/      \u001b[01;34mcropped_images\u001b[0m/  \u001b[01;34mfeatures\u001b[0m/  \u001b[01;34mlists\u001b[0m/\r\n",
      "\u001b[01;34mcleaned_images\u001b[0m/  \u001b[01;34mdims\u001b[0m/            \u001b[01;34mImages\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Images/  \n",
    "    Images of different breeds are in separate folders (The actual data)  \n",
    "- Annotations/  \n",
    "    Contains XML files with bounding box annotations for each image   \n",
    "(This basically describes the part of the image which best describes the dog, probably facial area)  \n",
    "- lists/\n",
    "    - file_list.mat - List of all files in the dataset\n",
    "    - train_list.mat - List and labels of all training images in dataset\n",
    "    - test_list.mat - List and labels of all test images in dataset\n",
    "- features/  \n",
    "    Contains the features of the network after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV optimization: True\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import scipy.io as sio   # for saving and loading mat files\n",
    "import os\n",
    "from xml.dom.minidom import parse    # XML DOM api\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv    # opencv for image-processing\n",
    "import time    # for timing code blocks\n",
    "\n",
    "# enable Optimization in case it's false with the following command\n",
    "# cv.setUseOptimized(True)\n",
    "print \"OpenCV optimization:\", cv.useOptimized()\n",
    "# here, it is already true\n",
    "\n",
    "# so that we can see the images in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# for moving half the images\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Just to show you how the xml data is formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<annotation>\r\n",
      "\t<folder>02104365</folder>\r\n",
      "\t<filename>n02104365_8998</filename>\r\n",
      "\t<source>\r\n",
      "\t\t<database>ImageNet database</database>\r\n",
      "\t</source>\r\n",
      "\t<size>\r\n",
      "\t\t<width>500</width>\r\n",
      "\t\t<height>333</height>\r\n",
      "\t\t<depth>3</depth>\r\n",
      "\t</size>\r\n",
      "\t<segment>0</segment>\r\n",
      "\t<object>\r\n",
      "\t\t<name>schipperke</name>\r\n",
      "\t\t<pose>Unspecified</pose>\r\n",
      "\t\t<truncated>0</truncated>\r\n",
      "\t\t<difficult>0</difficult>\r\n",
      "\t\t<bndbox>\r\n",
      "\t\t\t<xmin>139</xmin>\r\n",
      "\t\t\t<ymin>69</ymin>\r\n",
      "\t\t\t<xmax>305</xmax>\r\n",
      "\t\t\t<ymax>286</ymax>\r\n",
      "\t\t</bndbox>\r\n",
      "\t</object>\r\n",
      "\t<object>\r\n",
      "\t\t<name>schipperke</name>\r\n",
      "\t\t<pose>Unspecified</pose>\r\n",
      "\t\t<truncated>0</truncated>\r\n",
      "\t\t<difficult>0</difficult>\r\n",
      "\t\t<bndbox>\r\n",
      "\t\t\t<xmin>394</xmin>\r\n",
      "\t\t\t<ymin>113</ymin>\r\n",
      "\t\t\t<xmax>499</xmax>\r\n",
      "\t\t\t<ymax>230</ymax>\r\n",
      "\t\t</bndbox>\r\n",
      "\t</object>\r\n",
      "</annotation>"
     ]
    }
   ],
   "source": [
    "%cat /home/ashish/ml-projects/stanford_dogs/data/Annotation/n02104365-schipperke/n02104365_8998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So now, I will parse and extract the bounding box attributes, namely <code>xmin</code>, <code>xmax</code>, <code>ymin</code> and <code>ymax</code>.\n",
    "\n",
    "And for that, I will use the DOM API provided by Python. An another alternative is the SAX API and it can give be advantageous if you have pretty long documents. Since we don't have large documents and my familiarity with the DOM tree and its peculiarities, I chose the DOM API to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['schipperke', 139, 69, 305, 286], ['schipperke', 394, 113, 499, 230]]\n",
      "\n",
      "File contents:\n",
      "['schipperke', 'schipperke'] [[139, 69, 305, 286], [394, 113, 499, 230]]\n"
     ]
    }
   ],
   "source": [
    "xml_path = '/home/ashish/ml-projects/stanford_dogs/data/Annotation/n02104365-schipperke/n02104365_8998'\n",
    "\n",
    "domTree = parse(xml_path)\n",
    "annotation = domTree.documentElement\n",
    "objs = annotation.getElementsByTagName(\"object\") # since object is a global variable\n",
    "\n",
    "breeds = []\n",
    "\n",
    "for obj in objs:\n",
    "    breed = []\n",
    "    dims = []\n",
    "    name = obj.getElementsByTagName(\"name\")[0]\n",
    "    breed.append(str(name.childNodes[0].data))\n",
    "    \n",
    "    bndbox = obj.getElementsByTagName(\"bndbox\")[0]\n",
    "\n",
    "    dims.append(bndbox.getElementsByTagName(\"xmin\")[0])\n",
    "    dims.append(bndbox.getElementsByTagName(\"ymin\")[0])\n",
    "    dims.append(bndbox.getElementsByTagName(\"xmax\")[0])\n",
    "    dims.append(bndbox.getElementsByTagName(\"ymax\")[0])\n",
    "\n",
    "    dims = [int(dim.childNodes[0].data) for dim in dims]\n",
    "    for dim in dims: breed.append(dim)\n",
    "    breeds.append(breed)\n",
    "\n",
    "# print dims\n",
    "print breeds\n",
    "\n",
    "dir_name, file_name = os.path.split(os.path.abspath(xml_path))\n",
    "\n",
    "breed_dir = dir_name.split('/')[-1]\n",
    "# print breed_dir\n",
    "\n",
    "dims_dir = os.path.join(dir_name, '..', '..', 'dims', breed_dir)\n",
    "\n",
    "if not os.path.exists(dims_dir):\n",
    "    os.mkdir(dims_dir)\n",
    "\n",
    "dims_file = os.path.join(dims_dir, file_name)\n",
    "# print dims_file\n",
    "\n",
    "with open(dims_file, 'w') as outf:\n",
    "    for breed in breeds:\n",
    "        outf.write('{:s} {:d} {:d} {:d} {:d}\\n'.format(*breed))\n",
    "\n",
    "# Just checking if it went right\n",
    "print \"\\nFile contents:\"\n",
    "with open(dims_file, 'r') as f:\n",
    "    classes = [line.rstrip('\\n') for line in f]\n",
    "    names, dims = [], []\n",
    "    for cls in classes:\n",
    "        e = cls.split(' ')\n",
    "        names.append(str(e[0]))\n",
    "        dim = [int(i) for i in e[1:]]\n",
    "        dims.append(dim)\n",
    "    print names, dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case #0\n",
      "To write: [['schipperke', 73, 10, 405, 498]]\n",
      "File contents:\n",
      "['schipperke'] [[73, 10, 405, 498]]\n",
      "No. of files written: 20580\n"
     ]
    }
   ],
   "source": [
    "# Looping over all the files and storing the dims in a separate directory\n",
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "annot_dir = os.path.join(data_dir, 'Annotation')\n",
    "# print annot_dir\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(annot_dir):\n",
    "    breeds.append(os.path.join(annot_dir, folder))\n",
    "\n",
    "j = 0\n",
    "for breed in breeds:\n",
    "#     print breed\n",
    "    breed_name = breed.split('/')[-1]\n",
    "#     print breed_name\n",
    "    for xml in os.listdir(breed):\n",
    "        xml_path = os.path.join(breed, xml)\n",
    "#         print xml_path\n",
    "        try:\n",
    "            domTree = parse(xml_path)\n",
    "            annotation = domTree.documentElement\n",
    "            objs = annotation.getElementsByTagName(\"object\") # since object is a global variable\n",
    "            classes = []\n",
    "            for obj in objs:\n",
    "                cls = []\n",
    "                dims = []\n",
    "                name = obj.getElementsByTagName(\"name\")[0]\n",
    "                cls.append(str(name.childNodes[0].data))\n",
    "                \n",
    "                bndbox = obj.getElementsByTagName(\"bndbox\")[0]\n",
    "                dims.append(bndbox.getElementsByTagName(\"xmin\")[0])\n",
    "                dims.append(bndbox.getElementsByTagName(\"ymin\")[0])\n",
    "                dims.append(bndbox.getElementsByTagName(\"xmax\")[0])\n",
    "                dims.append(bndbox.getElementsByTagName(\"ymax\")[0])\n",
    "                \n",
    "                dims = [int(dim.childNodes[0].data) for dim in dims]\n",
    "                for dim in dims: cls.append(dim)\n",
    "                classes.append(cls)\n",
    "\n",
    "            dir_name, file_name = os.path.split(xml_path)\n",
    "            dims_dir = os.path.join(dir_name, '..', '..', 'dims', breed_name)\n",
    "\n",
    "            if not os.path.exists(dims_dir):\n",
    "                os.mkdir(dims_dir)\n",
    "\n",
    "            dims_file = os.path.join(dims_dir, file_name)\n",
    "\n",
    "            with open(dims_file, 'w') as outf:\n",
    "                for cls in classes:\n",
    "                    outf.write('{:s} {:d} {:d} {:d} {:d}\\n'.format(*cls))\n",
    "                    \n",
    "            if j == 0:\n",
    "                print \"Case #{}\".format(j)\n",
    "                print \"To write:\", classes\n",
    "                \n",
    "                with open(dims_file, 'r') as f:\n",
    "                    print \"File contents:\"\n",
    "                    classes = [line.rstrip('\\n') for line in f]\n",
    "                    names, dims = [], []\n",
    "                    for cls in classes:\n",
    "                        e = cls.split(' ')\n",
    "                        names.append(str(e[0]))\n",
    "                        dim = [int(i) for i in e[1:]]\n",
    "                        dims.append(dim)\n",
    "                    print names, dims\n",
    "                \n",
    "            j += 1\n",
    "        except:\n",
    "            print \"Problem with the xml file:\", xml_path\n",
    "            \n",
    "print \"No. of files written:\", j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped dir: /home/ashish/ml-projects/stanford_dogs/data/cleaned_images\n",
      "Cropped 3000 images into 3248 images\n",
      "Cropped 6000 images into 6441 images\n",
      "Cropped 8000 images into 8651 images\n",
      "Cropped 10000 images into 10825 images\n",
      "Cropped 12000 images into 12971 images\n",
      "Cropped 14000 images into 15144 images\n",
      "Cropped 16000 images into 17283 images\n",
      "Cropped 18000 images into 19405 images\n",
      "Cropped 20000 images into 21512 images\n",
      "Total Original images: 20580\n",
      "Total Cropped images: 22126\n"
     ]
    }
   ],
   "source": [
    "# cd to data_dir\n",
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "imgs_dir = os.path.join(data_dir, 'Images')\n",
    "cropped_dir = os.path.join(data_dir, 'cleaned_images')\n",
    "\n",
    "if not os.path.exists(cropped_dir):\n",
    "    os.mkdir(cropped_dir)\n",
    "\n",
    "print 'cropped dir:', cropped_dir\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(imgs_dir):\n",
    "    breeds.append(os.path.join(imgs_dir, folder))\n",
    "    \n",
    "# lmin, lmax, hmin, hmax = [0]*4\n",
    "j = 0\n",
    "k = 0\n",
    "st_time = time.time()\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed):\n",
    "        img_path = os.path.join(breed, img)\n",
    "        image = cv.imread(img_path)\n",
    "        \n",
    "        img_dir, img_file = img_path.split('/')[-2:]\n",
    "        img_file = img_file.split('.')[0]    # get rid of .jpg\n",
    "        dims_file = os.path.join(data_dir, 'dims', img_dir, img_file)\n",
    "        names = []\n",
    "        boxes = []\n",
    "        cropped_imgs = []\n",
    "        with open(dims_file, 'r') as f:\n",
    "            classes = [line.rstrip('\\n') for line in f]\n",
    "            names, dims = [], []\n",
    "            for cls in classes:\n",
    "                e = cls.split(' ')\n",
    "                names.append(str(e[0]))\n",
    "                box = [int(i) for i in e[1:]]\n",
    "                boxes.append(box)\n",
    "\n",
    "#         print names, boxes\n",
    "        numImages = 1\n",
    "        for name, box in zip(names, boxes):\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            cropped = image[xmin:xmax, ymin:ymax, :]\n",
    "            cropped_imgs.append(cropped)\n",
    "            \n",
    "            cropped_input_file = img.split('.')[0] + '_' + str(numImages) + '.jpg'\n",
    "            breed_dir = os.path.join(cropped_dir, name)\n",
    "            if not os.path.exists(breed_dir):\n",
    "                os.mkdir(breed_dir)\n",
    "            \n",
    "            cropped_file_path = os.path.join(breed_dir, cropped_input_file)\n",
    "            cv.imwrite(cropped_file_path, cropped)\n",
    "            \n",
    "            numImages += 1\n",
    "            k += 1 \n",
    "            \n",
    "#             cropped_output_path = os.path.join(cropped_dir, 'classes.csv')\n",
    "#             with open(cropped_output_path, 'a') as outf:\n",
    "#                 outf.write('{}, '.format(name))\n",
    "            \n",
    "#             if j == 0: lmin, hmin, _ = cropped.shape\n",
    "#             l, h, _ = cropped.shape\n",
    "#             if l < lmin: lmin = l\n",
    "#             if h < hmin: hmin = h\n",
    "#             if h > hmax: hmax = h\n",
    "#             if l > lmax: lmax = l\n",
    "#             if l >= 200 and h >= 200:\n",
    "#                 j += 1\n",
    "#             if (l >= 18 and l < 200) or (h >= 17 and h < 200): k += 1\n",
    "\n",
    "        \n",
    "#         if j == 1000:\n",
    "#             print 'img_file:', img\n",
    "#             print 'img_path:', img_path\n",
    "#             print 'dims_file:', dims_file\n",
    "#             print 'Original image dims:', image.shape\n",
    "#             plt.imshow(image)\n",
    "#             plt.show()\n",
    "#             for name, img, box in zip(names, cropped_imgs, boxes):\n",
    "#                 print img_path\n",
    "#                 print \"Class:\", name\n",
    "#                 print box\n",
    "#                 print \"Cropped image dims:\", img.shape\n",
    "#                 plt.imshow(img)\n",
    "#                 plt.show()\n",
    "\n",
    "        if j == 3000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 6000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 8000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 10000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 12000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 14000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 16000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 18000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        if j == 20000: print \"Cropped {} images into {} images.\\n Elapsed time: {}\" \\\n",
    "                            .format(j,k,time.time() - st_time)\n",
    "        \n",
    "        j += 1\n",
    "        \n",
    "print 'Total Original images:', j\n",
    "print 'Total Cropped images:', k\n",
    "\n",
    "# print '\\nExtremities:'\n",
    "# print 'lmin:', lmin, 'lmax:', lmax\n",
    "# print 'hmin:', hmin, 'hmax:', hmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped dir: /home/ashish/ml-projects/stanford_dogs/data/cropped_images\n",
      "Images cropped: 20580\n",
      "Images left: 0\n"
     ]
    }
   ],
   "source": [
    "# cd to data_dir\n",
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "imgs_dir = os.path.join(data_dir, 'Images')\n",
    "cropped_dir = os.path.join(data_dir, 'cropped_images')\n",
    "\n",
    "if not os.path.exists(cropped_dir):\n",
    "    os.mkdir(cropped_dir)\n",
    "\n",
    "print 'cropped dir:', cropped_dir\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(imgs_dir):\n",
    "    breeds.append(os.path.join(imgs_dir, folder))\n",
    "    \n",
    "lmin, lmax, hmin, hmax = [0]*4\n",
    "j = 0\n",
    "k = 0\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed):\n",
    "        img_path = os.path.join(breed, img)\n",
    "        image = cv.imread(img_path)\n",
    "        \n",
    "        img_dir, img_file = img_path.split('/')[-2:]\n",
    "        img_file = img_file.split('.')[0]    # get rid of .jpg\n",
    "        dims_file = os.path.join(data_dir, 'dims', img_dir, img_file)\n",
    "        names = []\n",
    "        boxes = []\n",
    "        cropped_imgs = []\n",
    "        with open(dims_file, 'r') as f:\n",
    "            classes = [line.rstrip('\\n') for line in f]\n",
    "            names, dims = [], []\n",
    "            for cls in classes:\n",
    "                e = cls.split(' ')\n",
    "                names.append(str(e[0]))\n",
    "#                 box = [int(i) for i in e[1:]]\n",
    "#                 boxes.append(box)\n",
    "\n",
    "#         print names, boxes\n",
    "#         numImages = 1\n",
    "        for name in names:\n",
    "#             ymin, xmin, ymax, xmax = box\n",
    "#             cropped = image[xmin:xmax, ymin:ymax, :]\n",
    "#             cropped_imgs.append(cropped)\n",
    "            \n",
    "#             cropped_input_file = img.split('.')[0] + '_' + str(numImages) + '.jpg'\n",
    "#             cropped_file_path = os.path.join(cropped_dir, cropped_input_file)\n",
    "#             cv.imwrite(cropped_file_path, cropped)\n",
    "            \n",
    "            cropped_output_path = os.path.join(cropped_dir, 'classes.csv')\n",
    "            with open(cropped_output_path, 'a') as outf:\n",
    "                outf.write('{}, '.format(name))\n",
    "            \n",
    "#             if j == 0: lmin, hmin, _ = cropped.shape\n",
    "#             l, h, _ = cropped.shape\n",
    "#             if l < lmin: lmin = l\n",
    "#             if h < hmin: hmin = h\n",
    "#             if h > hmax: hmax = h\n",
    "#             if l > lmax: lmax = l\n",
    "#             if l >= 200 and h >= 200:\n",
    "#                 j += 1\n",
    "#             if (l >= 18 and l < 200) or (h >= 17 and h < 200): k += 1\n",
    "\n",
    "        \n",
    "#         if j == 12000:\n",
    "#             print 'img_file:', img\n",
    "#             print 'img_path:', img_path\n",
    "#             print 'dims_file:', dims_file\n",
    "#             print 'Original image dims:', image.shape\n",
    "#             plt.imshow(image)\n",
    "#             plt.show()\n",
    "#             for name, img, box in zip(names, cropped_imgs, boxes):\n",
    "#                 print img_path\n",
    "#                 print \"Class:\", name\n",
    "#                 print box\n",
    "#                 print \"Cropped image dims:\", img.shape\n",
    "#                 plt.imshow(img)\n",
    "#                 plt.show()\n",
    "        \n",
    "        j += 1\n",
    "        \n",
    "print 'Images cropped:', j\n",
    "print 'Images left:', k\n",
    "\n",
    "# print '\\nExtremities:'\n",
    "# print 'lmin:', lmin, 'lmax:', lmax\n",
    "# print 'hmin:', hmin, 'hmax:', hmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating a smaller dataset\n",
    "Taking only the first 100 images from every class, cause constraints. :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1000\n",
      "Done with 2000\n",
      "Done with 5000\n",
      "Done with 8000\n",
      "Done with 10000\n",
      "Done with 12000\n",
      "images: 12000\n",
      "time: 98.5753428936\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "\n",
    "smaller_dataset_dir = os.path.join(data_dir, 'smaller_dataset')\n",
    "\n",
    "if not os.path.exists(smaller_dataset_dir):\n",
    "    os.mkdir(smaller_dataset_dir)\n",
    "    \n",
    "cleaned_imgs_dir = os.path.join(data_dir, 'cleaned_images')\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(cleaned_imgs_dir):\n",
    "    breeds.append(os.path.join(cleaned_imgs_dir, folder))\n",
    "    \n",
    "j = 0\n",
    "k = 0\n",
    "st_time = time.time()\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed)[:100]:\n",
    "        img_path = os.path.join(breed, img)\n",
    "#         image = cv.imread(img_path)\n",
    "        \n",
    "# So the breed_name is the class\n",
    "# and out_img_path is the output file\n",
    "\n",
    "#         l,h,_ = image.shape\n",
    "#         if l <= 224 or h <= 224: continue\n",
    "\n",
    "\n",
    "        breed_dir = os.path.join(smaller_dataset_dir, breed_name)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "        out_img_path = os.path.join(breed_dir, img)\n",
    "#         print img_path\n",
    "#         print out_img_path\n",
    "        \n",
    "        shutil.copyfile(img_path, out_img_path)\n",
    "\n",
    "#         cv.imwrite(out_img_path, image)\n",
    "    \n",
    "        j += 1\n",
    "        if j == 1000: print \"Done with {}\".format(j)\n",
    "        if j == 2000: print \"Done with {}\".format(j)\n",
    "        if j == 5000: print \"Done with {}\".format(j)\n",
    "        if j == 8000: print \"Done with {}\".format(j)\n",
    "        if j == 10000: print \"Done with {}\".format(j)\n",
    "        if j == 12000: print \"Done with {}\".format(j)\n",
    "        \n",
    "print \"images:\", j\n",
    "print \"time:\", time.time() - st_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Splitting data for Keras\n",
    "\n",
    "And now, Keras needs the data to be in another format. Wow! :/\n",
    "\n",
    "First for faster implementation, I am separating the smaller dataset I created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 12000\n",
      "time: 57.6521160603\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "\n",
    "keras_small_dir = os.path.join(data_dir, 'keras_small_ds')\n",
    "\n",
    "if not os.path.exists(keras_small_dir):\n",
    "    os.mkdir(keras_small_dir)\n",
    "    \n",
    "smaller_dataset_dir = os.path.join(data_dir, 'smaller_dataset')\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(smaller_dataset_dir):\n",
    "    breeds.append(os.path.join(smaller_dataset_dir, folder))\n",
    "    \n",
    "# k = 0\n",
    "j = 0\n",
    "st_time = time.time()\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed)[:70]:\n",
    "        img_path = os.path.join(breed, img)\n",
    "\n",
    "        breed_dir = os.path.join(keras_small_dir, 'train', breed_name)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "        out_img_path = os.path.join(breed_dir, img)\n",
    "#         print img_path\n",
    "#         print out_img_path\n",
    "        \n",
    "        shutil.copyfile(img_path, out_img_path)\n",
    "        j += 1\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed)[70:]:\n",
    "        img_path = os.path.join(breed, img)\n",
    "\n",
    "        breed_dir = os.path.join(keras_small_dir, 'validation', breed_name)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "        out_img_path = os.path.join(breed_dir, img)\n",
    "#         print img_path\n",
    "#         print out_img_path\n",
    "        \n",
    "        shutil.copyfile(img_path, out_img_path)\n",
    "        j += 1\n",
    "\n",
    "print \"images:\", j\n",
    "print \"time:\", time.time() - st_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating a miniature dataset for testing\n",
    "Because CPU :/  \n",
    "With 2 train and 1 test image per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "\n",
    "keras_mini_dir = os.path.join(data_dir, 'keras_mini_ds')\n",
    "\n",
    "if not os.path.exists(keras_mini_dir):\n",
    "    os.mkdir(keras_mini_dir)\n",
    "    \n",
    "smaller_dataset_dir = os.path.join(data_dir, 'smaller_dataset')\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(smaller_dataset_dir):\n",
    "    breeds.append(os.path.join(smaller_dataset_dir, folder))\n",
    "    \n",
    "# k = 0\n",
    "j = 0\n",
    "st_time = time.time()\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed)[3:9]:\n",
    "        img_path = os.path.join(breed, img)\n",
    "\n",
    "        keras_train_dir = os.path.join(keras_mini_dir, 'train')\n",
    "        if not os.path.exists(keras_train_dir):\n",
    "            os.mkdir(keras_train_dir)\n",
    "            \n",
    "        breed_dir = os.path.join(keras_mini_dir, 'train', breed_name)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "        out_img_path = os.path.join(breed_dir, img)\n",
    "#         print img_path\n",
    "#         print out_img_path\n",
    "        \n",
    "        shutil.copyfile(img_path, out_img_path)\n",
    "        j += 1\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    for img in os.listdir(breed)[9:10]:\n",
    "        img_path = os.path.join(breed, img)\n",
    "        \n",
    "        keras_validation_dir = os.path.join(keras_mini_dir, 'validation')\n",
    "        if not os.path.exists(keras_validation_dir):\n",
    "            os.mkdir(keras_validation_dir)\n",
    "            \n",
    "        breed_dir = os.path.join(keras_mini_dir, 'validation', breed_name)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "        out_img_path = os.path.join(breed_dir, img)\n",
    "#         print img_path\n",
    "#         print out_img_path\n",
    "        \n",
    "        shutil.copyfile(img_path, out_img_path)\n",
    "        j += 1\n",
    "\n",
    "print \"images:\", j\n",
    "print \"time:\", time.time() - st_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating Distributed datasets\n",
    "Because memory allocation constraints :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 8400\n",
      "time: 31.1456160545\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('Data_Preprocessing.ipynb'), '..', 'data'))\n",
    "\n",
    "keras_mini_dir = os.path.join(data_dir, 'keras_distributed_ds')\n",
    "\n",
    "if not os.path.exists(keras_mini_dir):\n",
    "    os.mkdir(keras_mini_dir)\n",
    "    \n",
    "smaller_dataset_dir = os.path.join(data_dir, 'smaller_dataset')\n",
    "\n",
    "breeds = []\n",
    "for folder in os.listdir(smaller_dataset_dir):\n",
    "    breeds.append(os.path.join(smaller_dataset_dir, folder))\n",
    "    \n",
    "# k = 0\n",
    "j = 0\n",
    "st_time = time.time()\n",
    "\n",
    "for breed in breeds:\n",
    "    breed_name = breed.split('/')[-1]\n",
    "    \n",
    "    for i in xrange(0,70,10):\n",
    "        for img in os.listdir(breed)[i:i+10]:\n",
    "            img_path = os.path.join(breed, img)\n",
    "            \n",
    "            train_dir = 'train' + '_' + str(i/10 + 1)\n",
    "            keras_train_dir = os.path.join(keras_mini_dir, train_dir)\n",
    "            if not os.path.exists(keras_train_dir):\n",
    "                os.mkdir(keras_train_dir)\n",
    "\n",
    "            breed_dir = os.path.join(keras_train_dir, breed_name)\n",
    "            if not os.path.exists(breed_dir):\n",
    "                os.mkdir(breed_dir)\n",
    "\n",
    "            out_img_path = os.path.join(breed_dir, img)\n",
    "#             print img_path\n",
    "#             print out_img_path\n",
    "\n",
    "            shutil.copyfile(img_path, out_img_path)\n",
    "            j += 1\n",
    "\n",
    "\n",
    "#     validation set #1 [70:80]\n",
    "#     validation set #2 [80:90]\n",
    "#     validation set #3 [90:100]\n",
    "#     for img in os.listdir(breed)[90:100]:\n",
    "#         img_path = os.path.join(breed, img)\n",
    "        \n",
    "#         keras_validation_dir = os.path.join(keras_mini_dir, 'validation_3')\n",
    "#         if not os.path.exists(keras_validation_dir):\n",
    "#             os.mkdir(keras_validation_dir)\n",
    "            \n",
    "#         breed_dir = os.path.join(keras_mini_dir, 'validation_3', breed_name)\n",
    "#         if not os.path.exists(breed_dir):\n",
    "#             os.mkdir(breed_dir)\n",
    "#         out_img_path = os.path.join(breed_dir, img)\n",
    "# #         print img_path\n",
    "# #         print out_img_path\n",
    "        \n",
    "#         shutil.copyfile(img_path, out_img_path)\n",
    "#         j += 1\n",
    "\n",
    "print \"images:\", j\n",
    "print \"time:\", time.time() - st_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
